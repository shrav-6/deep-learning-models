{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rseIeVXGzpS5",
        "outputId": "16e5cd28-5909-481a-e845-24b575d1dcd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nReplace the 0s in the constructor and backward function with the correct values. \\nThose classes which are already done for you have a note. \\n\\nThe classes are arranged in increasing order of difficulty. \\n'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "# The Variable class is complete. You do not need to make any changes here.\n",
        "class Variable(object):\n",
        "    def __init__(self, matrix):\n",
        "        self.value = np.array(matrix,dtype=np.float64)\n",
        "        if len(self.value.shape)==0:\n",
        "            self.value = self.value.reshape([1,1])\n",
        "        elif len(self.value.shape)!=2:\n",
        "            raise Exception(\"Only 2D matrices or scalars supported.\")\n",
        "\n",
        "        self.fanout = 0\n",
        "        self.gradient = 0\n",
        "\n",
        "\n",
        "    def __add__(self,other):\n",
        "        if not(isinstance(other, Variable)):\n",
        "            other = Variable(other)\n",
        "        register_operation(self,other)\n",
        "        return MatrixAddition(self,other)\n",
        "\n",
        "    def __truediv__(self,other):\n",
        "        if not(isinstance(other, Variable)):\n",
        "            other = Variable(other)\n",
        "        register_operation(self,other)\n",
        "        return MatrixDivision(self,other)\n",
        "\n",
        "    def __mul__(self,other):\n",
        "        if not(isinstance(other, Variable)):\n",
        "            other = Variable(other)\n",
        "        register_operation(self,other)\n",
        "        return ElementwiseMultiplication(self,other)\n",
        "\n",
        "    def __matmul__(self,other):\n",
        "        if not(isinstance(other, Variable)):\n",
        "            other = Variable(other)\n",
        "        register_operation(self,other)\n",
        "        return MatrixMultiplication(self,other)\n",
        "\n",
        "    def exp(self):\n",
        "        register_operation(self)\n",
        "        return Exp(self)\n",
        "\n",
        "    def log(self):\n",
        "        register_operation(self)\n",
        "        return Log(self)\n",
        "\n",
        "    def sum(self,axis):\n",
        "        register_operation(self)\n",
        "        return Sum(self,axis=axis)\n",
        "\n",
        "    def reset(self):\n",
        "        self.gradient = 0\n",
        "        self.fanout = 0\n",
        "\n",
        "## HELPER FUNCTIONS\n",
        "def propagate_gradients(*inputs):\n",
        "    \"\"\"\n",
        "    This function checks if the variable is \"ready\" to backpropagate.\n",
        "    Explain:\n",
        "\n",
        "    You do not have to modify the code.\n",
        "    \"\"\"\n",
        "    for variable in inputs:\n",
        "        variable.fanout -= 1\n",
        "        if variable.fanout == 0 and \"backward\" in dir(variable):\n",
        "            variable.backward()\n",
        "\n",
        "def register_operation(*inputs):\n",
        "    \"\"\"\n",
        "    This function counts the number of times a variable is used.\n",
        "    Explain:\n",
        "\n",
        "    You do not have to modify the code.\n",
        "    \"\"\"\n",
        "    for variable in inputs:\n",
        "        variable.fanout += 1\n",
        "\n",
        "\n",
        "def broadcast_gradients(gradient,variable):\n",
        "    \"\"\"\n",
        "    In some cases, the variable gets broadcasted during an operation.\n",
        "    Ex: In adding a [2,2] Matrix with [1,2] Vector, the Vector gets broadcasted.\n",
        "    During backpropagation, we need to appropriately \"broadcast\" the gradients to the variable.\n",
        "    Given the gradient and the variable, return the broadcasted version of the gradient.\n",
        "\n",
        "    The simplest case of broadcasting is when the shape of the gradient\n",
        "    matches the shape of the variable.\n",
        "\n",
        "    Write the code for the case when the shapes do not match.\n",
        "    \"\"\"\n",
        "    if gradient.shape == variable.value.shape:\n",
        "        return gradient\n",
        "    else:\n",
        "        #Code here.\n",
        "        None\n",
        "\n",
        "\"\"\"\n",
        "Replace the 0s in the constructor and backward function with the correct values.\n",
        "Those classes which are already done for you have a note.\n",
        "\n",
        "The classes are arranged in increasing order of difficulty.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0aaqqaxzpS7"
      },
      "outputs": [],
      "source": [
        "class Log(Variable):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "        v = Variable([[1,2,3]])\n",
        "        log_v = v.log()\n",
        "    \"\"\"\n",
        "    def __init__(self,v):\n",
        "        super().__init__(np.log(v.value)) #log of v - works\n",
        "        self.v = v\n",
        "\n",
        "    def backward(self):\n",
        "        self.v.gradient += self.gradient * 1 / self.v.value # d/dv(logv) = 1/v - to test\n",
        "\n",
        "        propagate_gradients(self.v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9t3h-C82zpS7"
      },
      "outputs": [],
      "source": [
        "v = Variable([[1,2,3]])\n",
        "log_v = v.log()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1LsBFYUzpS7",
        "outputId": "e140ba76-12e3-4fc6-ba0c-c00c0614afe6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.69314718, 1.09861229]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_v.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuUlIsutzpS8",
        "outputId": "6376fa5b-4ba8-48c7-b0bb-656b00dfc435"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0986122886681098"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "math.log(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtGj-tMTzpS8"
      },
      "outputs": [],
      "source": [
        "class Exp(Variable):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "        v = Variable([[1,2,3]])\n",
        "        exp_v = v.exp()\n",
        "    \"\"\"\n",
        "    def __init__(self,v):\n",
        "        super().__init__(np.exp(v.value)) #e^v - works\n",
        "        self.v = v\n",
        "\n",
        "    def backward(self):\n",
        "        self.v.gradient += self.gradient * np.exp(self.v.value) #d/dv(e^v) = e^v - to test\n",
        "\n",
        "        propagate_gradients(self.v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl7VAmCezpS8",
        "outputId": "d8fe0182-a515-43c7-9db9-53576e437b29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 2.71828183  7.3890561  20.08553692]]\n",
            "2.718281828459045 7.38905609893065 20.085536923187668\n"
          ]
        }
      ],
      "source": [
        "v = Variable([[1,2,3]])\n",
        "exp_v = v.exp()\n",
        "print(exp_v.value)\n",
        "print(math.exp(1), math.exp(2), math.exp(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVmkmu6_zpS8"
      },
      "outputs": [],
      "source": [
        "class Sigmoid(Variable):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "        v1 = Variable([[1,2],\n",
        "                       [3,4]])\n",
        "        v1_act = Sigmoid(v1)\n",
        "    \"\"\"\n",
        "    def __init__(self,v):\n",
        "        sigmoid = 1 / (1 + np.exp(-v.value)) #sig(v) = 1/(1+e^-v) - works\n",
        "        super().__init__(sigmoid)\n",
        "        self.v = v\n",
        "        self.v.fanout += 1\n",
        "\n",
        "    def backward(self):\n",
        "        self.v.gradient += self.gradient * self.value * (1 - self.value) #d/dx(sig(x) = sig(x)(1-sig(x)) - to test\n",
        "\n",
        "        propagate_gradients(self.v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDQVEyKlzpS8",
        "outputId": "51e5fae8-6471-4b1a-c90d-75da5f094a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.73105858 0.88079708]\n",
            " [0.95257413 0.98201379]]\n",
            "0.7310585786300049 0.8807970779778823 0.9525741268224334 0.9820137900379085\n"
          ]
        }
      ],
      "source": [
        "v1 = Variable([[1,2],\n",
        "                [3,4]])\n",
        "v1_act = Sigmoid(v1)\n",
        "print(v1_act.value)\n",
        "print(test_sigmoid(1), test_sigmoid(2), test_sigmoid(3), test_sigmoid(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlMuKCIszpS8"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def test_sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0MTaIDPzpS9"
      },
      "outputs": [],
      "source": [
        "class ReLU(Variable):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "        v1 = Variable([[1,2],\n",
        "                       [3,4]])\n",
        "        v1_act = ReLU(v1)\n",
        "    \"\"\"\n",
        "    def __init__(self,v):\n",
        "        relu = np.maximum(0, v.value) # relu = max(0,x) - works\n",
        "        super().__init__(relu)\n",
        "        self.v = v\n",
        "        self.v.fanout += 1\n",
        "\n",
        "    def backward(self):\n",
        "        self.v.gradient += self.gradient * (self.value > 0) # dy/dx(relu) = 1 for x > 0 and 0 for x <= 0\n",
        "\n",
        "        propagate_gradients(self.v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMteUuovzpS9",
        "outputId": "5c84966c-9b8e-4db4-c528-5c7fa0e18e4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 7.],\n",
              "       [0., 0.]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v1 = Variable([[-1,7],\n",
        "                [0,-3]])\n",
        "v1_act = ReLU(v1)\n",
        "v1_act.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sHY45_jzpS9"
      },
      "outputs": [],
      "source": [
        "class Tanh(Variable):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "        v1 = Variable([[1,2],\n",
        "                       [3,4]])\n",
        "        v1_act = Tanh(v1)\n",
        "    \"\"\"\n",
        "    def __init__(self,v):\n",
        "        #tanh = np.tanh(v.value) - shorter way\n",
        "        tanh = (np.exp(v.value) - np.exp(-v.value)) / (np.exp(v.value) + np.exp(-v.value)) # tanh(x) = (e^x - e^-x) / (e^x + e^-x) - works\n",
        "        super().__init__(tanh)\n",
        "        self.v = v\n",
        "        self.v.fanout += 1\n",
        "\n",
        "    def backward(self):\n",
        "        self.v.gradient += self.gradient * (1 - self.value**2) # d/dx(tanh(x)) = 1 - tanh(x)^2\n",
        "\n",
        "        propagate_gradients(self.v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euLhclLnzpS9",
        "outputId": "10651da3-d5ae-4980-ab8d-f926618257b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.76159416, 0.96402758],\n",
              "       [0.99505475, 0.9993293 ]])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v1 = Variable([[1,2],\n",
        "                [3,4]])\n",
        "v1_act = Tanh(v1)\n",
        "v1_act.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LccAzpvzpS-",
        "outputId": "a58ff04a-a39f-4fb4-ec6d-e583c8ffd779"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.76159416, 0.96402758],\n",
              "       [0.99505475, 0.9993293 ]])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v1_act.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O821NafOzpS-",
        "outputId": "c5e5c8e6-b81a-4892-f5ac-a1e97493114a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.999329299739067"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.tanh(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-tYH_uwzpS-"
      },
      "outputs": [],
      "source": [
        "# Medium Difficulty.\n",
        "class MatrixMultiplication(Variable):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "        v1 = Variable([[1,2],\n",
        "                       [3,4]])\n",
        "        v2 = Variable([[6],\n",
        "                       [7]])\n",
        "        v1_v2 = v1 @ v2\n",
        "    \"\"\"\n",
        "    def __init__(self,v1,v2):\n",
        "        super().__init__(np.matmul(v1.value, v2.value)) #matrix multiplication - works\n",
        "        self.v1 = v1\n",
        "        self.v2 = v2\n",
        "\n",
        "    def backward(self):\n",
        "        self.v1.gradient += np.matmul(self.gradient, self.v2.value.T) # if A = BC, then dA/dB = C.T and dA/dC = B\n",
        "        self.v2.gradient += np.matmul(self.v1.value.T, self.gradient)\n",
        "\n",
        "        propagate_gradients(self.v1,self.v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id21OEmSzpS-"
      },
      "outputs": [],
      "source": [
        "v1 = Variable([[1,2],\n",
        "                [3,4]])\n",
        "v2 = Variable([[0, 1],\n",
        "             [1, 0]])\n",
        "v1_v2 = v1 @ v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z67kUEazpS-",
        "outputId": "4f6cba58-19a9-4fab-93fc-ee9a535fcce9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2., 1.],\n",
              "       [4., 3.]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v1_v2.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVHyHl6qzpS-"
      },
      "outputs": [],
      "source": [
        "class MatrixAddition(Variable):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "        v1 = Variable([[1,2],\n",
        "                       [3,4]])\n",
        "        v2 = Variable([[6],\n",
        "                       [7]])\n",
        "        v1_v2 = v1 + v2\n",
        "    This has been done for you.\n",
        "    \"\"\"\n",
        "    def __init__(self,v1,v2):\n",
        "        super().__init__(v1.value+v2.value)\n",
        "\n",
        "        self.v1 = v1\n",
        "        self.v2 = v2\n",
        "\n",
        "    def backward(self):\n",
        "        # L X N\n",
        "        self.v1.gradient += broadcast_gradients(self.gradient,self.v1)\n",
        "        self.v2.gradient += broadcast_gradients(self.gradient,self.v2)\n",
        "\n",
        "        propagate_gradients(self.v1,self.v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfnSRB_UzpS-"
      },
      "outputs": [],
      "source": [
        "v1 = Variable([[1,2],\n",
        "                [3,4]])\n",
        "v2 = Variable([[6],\n",
        "                [7]])\n",
        "v1_v2 = v1 + v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPw6csiHzpS_",
        "outputId": "0fe85802-5982-4b89-ddcd-73e00cda9bb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 7.,  8.],\n",
              "       [10., 11.]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v1_v2.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkzZ8sg7zpS_"
      },
      "outputs": [],
      "source": [
        "class ElementwiseMultiplication(Variable):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "        v1 = Variable([[1,2,3]])\n",
        "        v2 = Variable([[4,5,6]])\n",
        "        v1_v2 = v1 * v2\n",
        "    \"\"\"\n",
        "    def __init__(self,v1,v2):\n",
        "        super().__init__(v1.value * v2.value) # Aij * Bij - works\n",
        "        self.v1 = v1\n",
        "        self.v2 = v2\n",
        "\n",
        "    def backward(self):\n",
        "        self.v1.gradient += broadcast_gradients(self.gradient * self.v2.value, self.v1) #other element * gradient - to test\n",
        "        self.v2.gradient += broadcast_gradients(self.gradient * self.v1.value, self.v2)\n",
        "\n",
        "        propagate_gradients(self.v1,self.v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zj8u3beozpS_",
        "outputId": "be1b400a-3373-4d75-ab26-f452c70c30bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 6., 3.]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v1 = Variable([[1,2,3]])\n",
        "v2 = Variable([[0,3,1]])\n",
        "v1_v2 = v1 * v2\n",
        "v1_v2.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cub7iYj7zpS_"
      },
      "outputs": [],
      "source": [
        "class MatrixDivision(Variable):\n",
        "    def __init__(self, v1, v2):\n",
        "        super().__init__(v1.value / v2.value) # works\n",
        "        self.v1 = v1\n",
        "        self.v2 = v2\n",
        "\n",
        "    def backward(self):\n",
        "        self.v1.gradient += broadcast_gradients(self.gradient / self.v2.value, self.v1) # A = B/C, then dA/dB = 1/C and dA/dC = -B/C^2 to test\n",
        "        self.v2.gradient += broadcast_gradients(self.gradient * (-self.v1.value / (self.v2.value**2)), self.v2)\n",
        "\n",
        "        propagate_gradients(self.v1, self.v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLdaVLYzzpS_",
        "outputId": "f81d00f0-1b33-4ba1-972a-22c9ce59edb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 2., 3.]])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v1 = Variable([[2,4,6]])\n",
        "v2 = Variable([[2]])\n",
        "v1_v2 = v1 / v2\n",
        "v1_v2.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHeFpVwizpS_"
      },
      "source": [
        "Explanation:\n",
        "\n",
        "The function takes two parameters: gradient and variable. gradient is the incoming gradient from the subsequent operation, and variable is the variable with respect to which the gradient is being calculated.\n",
        "\n",
        "The function checks if the shape of the gradient matches the shape of the variable.value. If they match, it means no broadcasting is needed, and the original gradient is returned.\n",
        "\n",
        "If the shapes do not match, broadcasting is required. The axis_to_sum list is created to identify the axes along which the broadcasting should be performed. For each axis where the size of the gradient is 1, it means broadcasting is needed along that axis.\n",
        "\n",
        "np.sum(gradient, axis=tuple(axis_to_sum), keepdims=True) performs the broadcasting. It sums the gradient along the specified axes, effectively extending its dimensions to match the shape of the variable.\n",
        "\n",
        "The result is the broadcasted version of the gradient, which can be added to the original gradient during backpropagation. This ensures that the gradients are appropriately aligned with the dimensions of the variables involved in the operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GK34IekdzpTA"
      },
      "outputs": [],
      "source": [
        "def broadcast_gradients(gradient, variable):\n",
        "    \"\"\"\n",
        "    In some cases, the variable gets broadcasted during an operation.\n",
        "    Ex: In adding a [2,2] Matrix with [1,2] Vector, the Vector gets broadcasted.\n",
        "    During backpropagation, we need to appropriately \"broadcast\" the gradients to the variable.\n",
        "    Given the gradient and the variable, return the broadcasted version of the gradient.\n",
        "\n",
        "    The simplest case of broadcasting is when the shape of the gradient\n",
        "    matches the shape of the variable.\n",
        "\n",
        "    Write the code for the case when the shapes do not match.\n",
        "    \"\"\"\n",
        "    if gradient.shape == variable.value.shape:\n",
        "        return gradient\n",
        "    else:\n",
        "        # Broadcasting is performed by summing along the appropriate axis\n",
        "        axis_to_sum = [i for i in range(len(variable.value.shape)) if gradient.shape[i] == 1]\n",
        "        return np.sum(gradient, axis=tuple(axis_to_sum), keepdims=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjFv9bO4zpTB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}